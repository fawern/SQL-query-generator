{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings \nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-11T05:45:03.756741Z","iopub.execute_input":"2024-04-11T05:45:03.757524Z","iopub.status.idle":"2024-04-11T05:45:03.761787Z","shell.execute_reply.started":"2024-04-11T05:45:03.757490Z","shell.execute_reply":"2024-04-11T05:45:03.760929Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2024-04-11T05:45:03.902745Z","iopub.execute_input":"2024-04-11T05:45:03.903412Z","iopub.status.idle":"2024-04-11T05:45:04.934394Z","shell.execute_reply.started":"2024-04-11T05:45:03.903385Z","shell.execute_reply":"2024-04-11T05:45:04.933462Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Thu Apr 11 05:45:04 2024       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n| N/A   38C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n|   1  Tesla T4                       Off | 00000000:00:05.0 Off |                    0 |\n| N/A   39C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n|  No running processes found                                                           |\n+---------------------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -q -U transformers torch==2.2.1 datasets huggingface_hub wandb\n!pip install -q -U accelerate bitsandbytes peft trl python-dotenv\n!echo \"Installations completed!\"","metadata":{"execution":{"iopub.status.busy":"2024-04-11T05:45:08.794707Z","iopub.execute_input":"2024-04-11T05:45:08.795080Z","iopub.status.idle":"2024-04-11T05:47:55.322656Z","shell.execute_reply.started":"2024-04-11T05:45:08.795049Z","shell.execute_reply":"2024-04-11T05:47:55.321156Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Installations completed!\n","output_type":"stream"}]},{"cell_type":"code","source":"import transformers\nimport datasets\nimport trl\nimport accelerate\nimport peft\nimport bitsandbytes\nimport torch\nimport huggingface_hub\nimport wandb\n\nprint(\"transformers version:\", transformers.__version__)\nprint(\"datasets version:\", datasets.__version__)\nprint(\"trl version:\", trl.__version__)\nprint(\"accelerate version:\", accelerate.__version__)\nprint(\"peft version:\", peft.__version__)\nprint(\"bitsandbytes version:\", bitsandbytes.__version__)\nprint(\"torch version:\", torch.__version__)\nprint(\"huggingface_hub version:\", huggingface_hub.__version__)\nprint(\"wandb version:\", wandb.__version__)","metadata":{"execution":{"iopub.status.busy":"2024-04-11T05:47:55.324998Z","iopub.execute_input":"2024-04-11T05:47:55.325313Z","iopub.status.idle":"2024-04-11T05:48:03.805584Z","shell.execute_reply.started":"2024-04-11T05:47:55.325285Z","shell.execute_reply":"2024-04-11T05:48:03.804711Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"transformers version: 4.39.3\ndatasets version: 2.18.0\ntrl version: 0.8.1\naccelerate version: 0.29.2\npeft version: 0.10.0\nbitsandbytes version: 0.43.0\ntorch version: 2.2.1+cu121\nhuggingface_hub version: 0.22.2\nwandb version: 0.16.6\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_dataset, Dataset\nfrom datasets.exceptions import DatasetNotFoundError\n\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, TrainingArguments\nfrom torch import bfloat16\n\nfrom peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model, PeftModel\nfrom trl import SFTTrainer\n\nfrom huggingface_hub import notebook_login, logging\nimport wandb","metadata":{"execution":{"iopub.status.busy":"2024-04-11T05:48:03.806996Z","iopub.execute_input":"2024-04-11T05:48:03.807633Z","iopub.status.idle":"2024-04-11T05:48:15.713451Z","shell.execute_reply.started":"2024-04-11T05:48:03.807583Z","shell.execute_reply":"2024-04-11T05:48:15.712651Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"2024-04-11 05:48:07.234531: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-11 05:48:07.234656: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-11 05:48:07.402845: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"def load_data(use_my_dataset=True):\n  try:\n    if use_my_dataset:\n      print(\"Using fawern/Text-to-sql-query-generation\")\n      dataset = load_dataset(\"fawern/Text-to-sql-query-generation\", split='train')\n      print(dataset[0])\n    else:\n      raise DatasetNotFoundError\n\n  except DatasetNotFoundError:\n    print(\"Clinton/Text-to-sql-v1\")\n    dataset = load_dataset(\"Clinton/Text-to-sql-v1\", split='train')\n\n    print(dataset[0])\n\n    def get_prompt(text):\n      input_text = text['instruction']\n      output_text = text['response']\n\n      prompt = f\"\"\" <s> [INST] You are a SQL query generator (text-to-sql). Your task is to generate a SQL query from the given question.\n      Question : {input_text} [/INST] SQL Query : {output_text} </s>\"\"\"\n      return {'prompt' : prompt}\n\n    dataset = dataset.map(get_prompt, remove_columns=dataset.features)\n    dataset.push_to_hub(\"fawern/Text-to-sql-query-generation\")\n\n  train_rate = int(len(dataset) * 0.8)\n\n  train_dataset = Dataset.from_dict(dataset[:train_rate])\n  val_dataset = Dataset.from_dict(dataset[train_rate:])\n\n  return train_dataset, val_dataset\n\ntrain_dataset, val_dataset = load_data()","metadata":{"execution":{"iopub.status.busy":"2024-04-11T05:48:15.716063Z","iopub.execute_input":"2024-04-11T05:48:15.717403Z","iopub.status.idle":"2024-04-11T05:48:21.153370Z","shell.execute_reply.started":"2024-04-11T05:48:15.717374Z","shell.execute_reply":"2024-04-11T05:48:21.152368Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Using fawern/Text-to-sql-query-generation\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/283 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"845d822a14bf410b93a5199454f4389e"}},"metadata":{}},{"name":"stderr","text":"Downloading data: 100%|██████████| 31.8M/31.8M [00:00<00:00, 40.3MB/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/262208 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d66538f2cca472c9b57c12c866d6e45"}},"metadata":{}},{"name":"stdout","text":"{'prompt': ' <s> [INST] You are a SQL query generator (text-to-sql). Your task is to generate a SQL query from the given question.\\n      Question : Name the home team for carlton away team [/INST] SQL Query : SELECT home_team FROM table_name_77 WHERE away_team = \"carlton\" </s>'}\n","output_type":"stream"}]},{"cell_type":"code","source":"try:\n    from google.colab import drive\n    import os\n    \n    print(\"Using Google Colab\")\n    drive.mount('/content/drive')\n    os.chdir('/content/drive/MyDrive/SQL-Query-Generator/')\n    \n    load_dotenv()\n\n    huggingface_token = os.environ.get(\"HUGGINGFACE_TOKEN\")\n    wandb_api_key = os.environ.get(\"WANDB_API_KEY\")\n\n    print(huggingface_token)\n\n    wandb.login(key=wandb_api_key)\n\n#     HUGGINGFACE_TOKEN = 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\n#     WANDB_API_KEY = ac4525a27cdcb34c068674c5fed00841eb0d9f4c\n    \nexcept ModuleNotFoundError:\n    notebook_login()\n    logging.set_verbosity(logging.CRITICAL)\n    wandb.login()\n    print(\"Using other environment\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model_name= 'defog/sqlcoder-7b-2'\n\ntokenizer = AutoTokenizer.from_pretrained(base_model_name)\ntokenizer.add_eos_token = True\ntokenizer.padding_side = 'right'\ntokenizer.pad_token = tokenizer.eos_token\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit = True,\n    bnb_4bit_quant_type='nf4',\n    bnb_4bit_use_double_quant=False,\n    bnb_4bit_compute_dtype=bfloat16\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model_name, \n    quantization_config=bnb_config,\n    torch_dtype=bfloat16,\n    device_map='auto'\n)\n\nmodel.gradient_checkpointing_enable()\n\nmodel = prepare_model_for_kbit_training(model)","metadata":{"execution":{"iopub.status.busy":"2024-04-11T05:49:13.724165Z","iopub.execute_input":"2024-04-11T05:49:13.724526Z","iopub.status.idle":"2024-04-11T05:50:33.253554Z","shell.execute_reply.started":"2024-04-11T05:49:13.724499Z","shell.execute_reply":"2024-04-11T05:50:33.252724Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aede45e2006b42c3b0b9e944a77d9f8a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbc2064a3b5542fabf6876f5d3b69226"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28206a067dfe4f50bee058501224eb1c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/3.59G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9ea44a38cfd43d0b87c499cdf93bd11"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e473459cc54c482395e042e1625c2e1b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3eb00b9c048b4e8ea82a8dc207044201"}},"metadata":{}}]},{"cell_type":"code","source":" lora_config = LoraConfig(\n    r=8,\n    lora_alpha=16,\n    bias='none',\n    lora_dropout=0.05,\n    task_type='CAUSAL_LM',\n    target_modules=[\n    \"q_proj\",\n    \"k_proj\",\n    \"v_proj\",\n    \"o_proj\",\n    \"gate_proj\",\n    \"up_proj\",\n    \"down_proj\",\n    \"lm_head\",\n    ]\n)\n\nmodel = get_peft_model(model, lora_config)","metadata":{"execution":{"iopub.status.busy":"2024-04-11T05:50:33.255296Z","iopub.execute_input":"2024-04-11T05:50:33.255577Z","iopub.status.idle":"2024-04-11T05:50:33.772595Z","shell.execute_reply.started":"2024-04-11T05:50:33.255553Z","shell.execute_reply":"2024-04-11T05:50:33.771880Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir='./sql-coder-7B-2-results',\n    num_train_epochs=3,\n    learning_rate=2e-4,\n    per_device_train_batch_size=4,\n    gradient_accumulation_steps=41,\n    optim='paged_adamw_32bit',\n    save_strategy='steps', \n    save_steps=25,\n    weight_decay=0.001,\n    max_steps=50, \n    evaluation_strategy='steps',\n    eval_steps=25,\n    do_eval=True,\n    report_to='wandb'\n)\n\ntrainer = SFTTrainer(\n    model = model ,\n    args=training_args,\n    tokenizer = tokenizer,\n    train_dataset=train_dataset,\n    eval_dataset = val_dataset,\n    peft_config=lora_config,\n    dataset_text_field='prompt'\n)\n\nmodel.config.use_cache=False","metadata":{"execution":{"iopub.status.busy":"2024-04-11T05:50:33.773721Z","iopub.execute_input":"2024-04-11T05:50:33.774001Z","iopub.status.idle":"2024-04-11T05:51:15.804094Z","shell.execute_reply.started":"2024-04-11T05:50:33.773977Z","shell.execute_reply":"2024-04-11T05:51:15.803511Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/209766 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ac021c41a3a41ebad07cc38357669d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/52442 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5d79e807fd542998ad318f124dec8c1"}},"metadata":{}}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-04-11T05:51:15.806329Z","iopub.execute_input":"2024-04-11T05:51:15.807135Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240411_055116-0n1c1blx</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/fawern/huggingface/runs/0n1c1blx' target=\"_blank\">efficient-plant-13</a></strong> to <a href='https://wandb.ai/fawern/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/fawern/huggingface' target=\"_blank\">https://wandb.ai/fawern/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/fawern/huggingface/runs/0n1c1blx' target=\"_blank\">https://wandb.ai/fawern/huggingface/runs/0n1c1blx</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='26' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [26/50 2:41:11 < 2:41:11, 0.00 it/s, Epoch 0.02/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>\n    <div>\n      \n      <progress value='2444' max='6556' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2444/6556 5:11:41 < 8:44:38, 0.13 it/s]\n    </div>\n    "},"metadata":{}}]},{"cell_type":"code","source":"trained_model_name = \"fawern/sqlcoder-7b2-SQL-query-generator\"\ntrainer.model.push_to_hub(trained_model_name)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'completed'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}